{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Agentune Analyze\n",
    "\n",
    "Welcome to Agentune Analyze! This tutorial will walk you through the fundamentals of using the library to analyze conversation data and generate insights.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- How to load multi-table conversation data\n",
    "- Running analysis on conversations\n",
    "- Exploring discovered features and their predictive value\n",
    "- Generating action recommendations from conversation patterns\n",
    "- Properly managing resources with RunContext\n",
    "\n",
    "**Estimated time**: 10-15 minutes\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Python >=3.12\n",
    "- Agentune Analyze installed (`pip install agentune-analyze`)\n",
    "- Jupyter Notebook installed (`pip install jupyter`)\n",
    "- OpenAI API key ([get one here](https://platform.openai.com/api-keys))\n",
    "\n",
    "**Note**: The sample data attached to this notebook is provided strictly for research and AI model development. Commercial use,\n",
    "resale, or redistribution is prohibited.\n",
    "**Note for Mac users**: If you encounter errors related to lightgbm, you may need to install OpenMP first: `brew install libomp`. See the [LightGBM macOS installation guide](https://lightgbm.readthedocs.io/en/latest/Installation-Guide.html) for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Setup and Imports\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T12:21:35.571338Z",
     "start_time": "2025-11-11T12:21:32.757404Z"
    }
   },
   "source": "import os\nfrom pathlib import Path\n\nimport polars as pl\n\n# Agentune Analyze imports\nfrom agentune.analyze.api.base import RunContext\nfrom agentune.analyze.feature.problem import ProblemDescription",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T12:21:42.566745Z",
     "start_time": "2025-11-11T12:21:42.562804Z"
    }
   },
   "source": [
    "# Recommended: Set the environment variable before starting Jupyter\n",
    "# export OPENAI_API_KEY=\"your-api-key-here\"\n",
    "\n",
    "# Alternative: Set it in the notebook (not recommended for production)\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"\n",
    "\n",
    "# Verify it's set\n",
    "if 'OPENAI_API_KEY' not in os.environ:\n",
    "    raise ValueError('Please set OPENAI_API_KEY environment variable')\n",
    "\n",
    "print('‚úì Environment configured')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Environment configured\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Load Sample Data\n",
    "\n",
    "We'll work with auto insurance customer service conversations. The dataset consists of two tables:\n",
    "- **Conversations table** (conversations.csv): One row per conversation with outcome and duration\n",
    "- **Messages table** (messages.csv): Individual message turns within each conversation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T12:21:48.964475Z",
     "start_time": "2025-11-11T12:21:48.949871Z"
    }
   },
   "source": [
    "# Define data paths\n",
    "data_dir = Path('data')\n",
    "conversations_path = data_dir / 'conversations.csv'\n",
    "messages_path = data_dir / 'messages.csv'\n",
    "\n",
    "# Load data using Polars\n",
    "conversations_df = pl.read_csv(conversations_path)\n",
    "messages_df = pl.read_csv(messages_path)\n",
    "\n",
    "print(f'Loaded {len(conversations_df)} conversations')\n",
    "print(f'Loaded {len(messages_df)} message turns')\n",
    "print(f'\\nConversations columns: {conversations_df.columns}')\n",
    "print(f'Messages columns: {messages_df.columns}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 101 conversations\n",
      "Loaded 16823 message turns\n",
      "\n",
      "Conversations columns: ['conversation_id', 'outcome', 'duration_seconds']\n",
      "Messages columns: ['conversation_id', 'timestamp', 'message', 'author']\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T12:21:52.964284Z",
     "start_time": "2025-11-11T12:21:52.957546Z"
    }
   },
   "source": [
    "# Show outcome distribution\n",
    "print('Outcome distribution:')\n",
    "print(conversations_df.group_by('outcome').agg(pl.len()).sort('len', descending=True))\n",
    "\n",
    "print(f'\\nTotal conversations: {len(conversations_df)}')\n",
    "print(f'Total messages: {len(messages_df)}')\n",
    "print(f'Average messages per conversation: {len(messages_df) / len(conversations_df):.1f}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome distribution:\n",
      "shape: (6, 2)\n",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ outcome                         ‚îÜ len ‚îÇ\n",
      "‚îÇ ---                             ‚îÜ --- ‚îÇ\n",
      "‚îÇ str                             ‚îÜ u32 ‚îÇ\n",
      "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
      "‚îÇ customer not interested         ‚îÜ 32  ‚îÇ\n",
      "‚îÇ process paused - customer need‚Ä¶ ‚îÜ 28  ‚îÇ\n",
      "‚îÇ process paused - customer need‚Ä¶ ‚îÜ 17  ‚îÇ\n",
      "‚îÇ customer objections not handle‚Ä¶ ‚îÜ 12  ‚îÇ\n",
      "‚îÇ no quote - ineligible customer  ‚îÜ 11  ‚îÇ\n",
      "‚îÇ buy                             ‚îÜ 1   ‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
      "\n",
      "Total conversations: 101\n",
      "Total messages: 16823\n",
      "Average messages per conversation: 166.6\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Create RunContext\n",
    "\n",
    "The `RunContext` is your main entry point to Agentune Analyze. It manages all resources including database connections, HTTP clients, and LLM instances."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T12:21:57.561119Z",
     "start_time": "2025-11-11T12:21:56.996536Z"
    }
   },
   "source": [
    "# Create context\n",
    "ctx = await RunContext.create()\n",
    "\n",
    "print('‚úì RunContext created')\n",
    "print('  - Database connection available')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì RunContext created\n",
      "  - Database connection available\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The RunContext will be used throughout the tutorial. Remember to close it when you're done (we'll show this at the end)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Load Data into DuckDB\n",
    "\n",
    "Now we'll load our Polars DataFrames into DuckDB tables, which Agentune Analyze uses for efficient data processing."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T12:22:00.216345Z",
     "start_time": "2025-11-11T12:22:00.171585Z"
    }
   },
   "source": [
    "# Load conversations table (main table: one row per conversation)\n",
    "conversations_table = await ctx.data.from_csv(conversations_path).copy_to_table('conversations')\n",
    "\n",
    "print(f'‚úì Loaded conversations table: {conversations_table.name}')\n",
    "print(f'  Schema: {conversations_table.schema}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Loaded conversations table: \"memory\".\"main\".\"conversations\"\n",
      "  Schema: Schema(cols=(Field(name='conversation_id', dtype=SimpleDtype(name='str', duckdb_type=VARCHAR, polars_type=String)), Field(name='outcome', dtype=SimpleDtype(name='str', duckdb_type=VARCHAR, polars_type=String)), Field(name='duration_seconds', dtype=SimpleDtype(name='float64', duckdb_type=DOUBLE, polars_type=Float64))))\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T12:22:03.982384Z",
     "start_time": "2025-11-11T12:22:03.817286Z"
    }
   },
   "source": [
    "# Load messages table\n",
    "messages_table = await ctx.data.from_csv(messages_path).copy_to_table('messages')\n",
    "\n",
    "print(f'‚úì Loaded messages table: {messages_table.name}')\n",
    "print(f'  Schema: {messages_table.schema}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Loaded messages table: \"memory\".\"main\".\"messages\"\n",
      "  Schema: Schema(cols=(Field(name='conversation_id', dtype=SimpleDtype(name='str', duckdb_type=VARCHAR, polars_type=String)), Field(name='timestamp', dtype=SimpleDtype(name='timestamp', duckdb_type=TIMESTAMP_MS, polars_type=Datetime(time_unit='ms', time_zone=None))), Field(name='message', dtype=SimpleDtype(name='str', duckdb_type=VARCHAR, polars_type=String)), Field(name='author', dtype=SimpleDtype(name='str', duckdb_type=VARCHAR, polars_type=String))))\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## 5. Define Table Relationships\n\nNow that both tables are loaded, we need to tell Agentune Analyze how they relate to each other for conversation analysis.",
   "metadata": {}
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T18:10:44.075971Z",
     "start_time": "2025-11-10T18:10:44.071980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define how the messages table relates to conversations\n",
    "join_strategy = messages_table.join_strategy.conversation(\n",
    "    name='messages',\n",
    "    main_table_key_col='conversation_id',\n",
    "    key_col='conversation_id',\n",
    "    timestamp_col='timestamp',\n",
    "    role_col='author',\n",
    "    content_col='message'\n",
    ")\n",
    "\n",
    "print('‚úì Join strategy defined for multi-turn conversations')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Join strategy defined for multi-turn conversations\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## 6. Split Data\n",
    "\n",
    "Agentune Analyze splits your data into subsets for feature generation and evaluation."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T18:10:44.126659Z",
     "start_time": "2025-11-10T18:10:44.099148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split the conversations table (main table)\n",
    "split_data = await conversations_table.split(train_fraction=0.9)\n",
    "\n",
    "print('‚úì Data split complete')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Data split complete\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**Note**: The data is split into training (90%) and test (10%) subsets for analysis."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## 7. Define the Problem\n",
    "\n",
    "Tell Agentune Analyze what you're trying to predict. In our case, we want to predict the conversation outcome."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T18:10:44.150292Z",
     "start_time": "2025-11-10T18:10:44.146656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the prediction problem\n",
    "# Note: target_desired_outcome must exactly match a value from the outcome column\n",
    "# (see the outcome distribution shown in section 2 above)\n",
    "problem = ProblemDescription(\n",
    "    target_column='outcome',\n",
    "    problem_type='classification',\n",
    "    target_desired_outcome='process paused - customer needs to consider the offer',  # The outcome we want to optimize for\n",
    "    name='Customer Service Conversation Outcome Prediction',\n",
    "    description='Analyze the outcome of auto insurance customer service conversations, and suggest improvements for increasing insurance sales',\n",
    "    target_description='The final outcome of the conversation (buy, not interested, needs more info, etc.)'\n",
    ")\n",
    "\n",
    "print('‚úì Problem defined')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Problem defined\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## 8. Run Analysis\n",
    "\n",
    "Now comes the exciting part! We'll run analysis, which will:\n",
    "1. Generate candidate features from conversation analysis\n",
    "2. Evaluate each feature's predictive power\n",
    "3. Select the most valuable features"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T18:19:54.579275Z",
     "start_time": "2025-11-10T18:10:44.164324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run analysis!\n",
    "# This will take a few minutes to analyze conversation patterns\n",
    "\n",
    "print('Starting analysis...')\n",
    "print('This may take 5-10 minutes to analyze conversation patterns...')\n",
    "\n",
    "results = await ctx.ops.analyze(\n",
    "    problem_description=problem,\n",
    "    main_input=split_data,\n",
    "    secondary_tables=[messages_table],\n",
    "    join_strategies=[join_strategy]\n",
    ")\n",
    "\n",
    "print('\\n‚úì Analysis complete!')\n",
    "print(f'  Discovered {len(results.features)} features')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis...\n",
      "This may take 5-10 minutes to analyze conversation patterns...\n",
      "\n",
      "‚úì Analysis complete!\n",
      "  Discovered 57 features\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## 9. Explore the Results\n",
    "\n",
    "Let's examine what features were discovered and how predictive they are."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T18:19:55.111929Z",
     "start_time": "2025-11-10T18:19:55.107181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Show discovered features\n",
    "print('Top 10 Discovered Features:\\n')\n",
    "for i, feature_with_stats in enumerate(results.features_with_train_stats[:10], 1):\n",
    "    feature = feature_with_stats.feature\n",
    "    stats = feature_with_stats.stats\n",
    "\n",
    "    print(f'{i}. {feature.name}')\n",
    "    print(f'   Description: {feature.description}')\n",
    "    print(f'   Type: {feature.dtype}')\n",
    "    print(f'   R¬≤: {stats.relationship.r_squared:.4f}')\n",
    "    print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Discovered Features:\n",
      "\n",
      "1. primary_objection_type\n",
      "   Description: What was the main customer objection that prevented a decision? (one of: price_high, need_time, missing_info, not_interested, coverage_mismatch, trust_concern, schedule_conflict, none)\n",
      "   Type: Enum[price_high, not_interested, need_time, none, missing_info, schedule_conflict, coverage_mismatch, trust_concern, _other_]\n",
      "   R¬≤: 0.0897\n",
      "\n",
      "2. follow_up_channel\n",
      "   Description: What follow-up channel was agreed? (one of: callback, email, text_link, none)\n",
      "   Type: Enum[text_link, none, callback, email, _other_]\n",
      "   R¬≤: 0.0797\n",
      "\n",
      "3. decision_maker_present\n",
      "   Description: Was the primary decision maker for the policy on the call? (one of: yes_customer, yes_other, no, unknown)\n",
      "   Type: Enum[yes_customer, no, _other_]\n",
      "   R¬≤: 0.1042\n",
      "\n",
      "4. carrier_connection_result\n",
      "   Description: Result of carrier transfer attempt (one of: connected, no_agent_available, customer_refused, not_attempted)\n",
      "   Type: Enum[connected, not_attempted, no_agent_available, customer_refused, _other_]\n",
      "   R¬≤: 0.0815\n",
      "\n",
      "5. close_attempt_response\n",
      "   Description: Customer response to close attempt (one of: accepted, declined_price, declined_need_time, declined_missing_info, undecided, not_attempted)\n",
      "   Type: Enum[declined_need_time, accepted, declined_price, undecided, not_attempted, declined_missing_info, _other_]\n",
      "   R¬≤: 0.0606\n",
      "\n",
      "6. quote_delivery_method\n",
      "   Description: How was the quote (or link) delivered? (one of: phone_voice, text_link, email, none)\n",
      "   Type: Enum[phone_voice, none, text_link, email, _other_]\n",
      "   R¬≤: 0.0633\n",
      "\n",
      "7. customer_explicit_pause\n",
      "   Description: Did the customer explicitly say they need time to think/consult or will decide later? (Y/N)\n",
      "   Type: bool\n",
      "   R¬≤: 0.0472\n",
      "\n",
      "8. quote_requires_additional_info\n",
      "   Description: Did the agent state that finalizing the quote depends on receiving additional information later? (Y/N)\n",
      "   Type: bool\n",
      "   R¬≤: 0.0383\n",
      "\n",
      "9. follow_up_scheduled\n",
      "   Description: Was a follow-up action scheduled (call-back date/time, email, or text link)? (Y/N)\n",
      "   Type: bool\n",
      "   R¬≤: 0.0534\n",
      "\n",
      "10. missing_customer_info_flag\n",
      "   Description: Did the agent indicate that required customer information (e.g., VIN, full address, carrier name) was missing? (Y/N)\n",
      "   Type: bool\n",
      "   R¬≤: 0.0508\n",
      "\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## 10. Generate Action Recommendations\n",
    "\n",
    "Based on the conversation patterns, generate actionable recommendations for improving outcomes."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T18:22:19.850571Z",
     "start_time": "2025-11-10T18:19:55.122571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Generate recommendations\n",
    "print('Generating action recommendations...')\n",
    "\n",
    "recommendations = await ctx.ops.recommend_conversation_actions(\n",
    "    analyze_input=split_data,\n",
    "    analyze_results=results\n",
    ")\n",
    "\n",
    "print('\\n‚úì Generated recommendations' if recommendations else '\\n‚úì No recommendations generated')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating action recommendations...\n",
      "\n",
      "‚úì Generated recommendations\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T18:22:20.455470Z",
     "start_time": "2025-11-10T18:22:20.451660Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display top 5 recommendations\n",
    "print('\\nTop 5 Recommendations:\\n')\n",
    "for i, rec in enumerate(recommendations.recommendations[:5], 1):\n",
    "    print(f'{i}. {rec.title}')\n",
    "    print(f'   Rationale: {rec.rationale}')\n",
    "    print(f'   Description: {rec.description}')\n",
    "    print(f'   Evidence: {rec.evidence}')\n",
    "    print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Recommendations:\n",
      "\n",
      "1. Recommendation 1\n",
      "   Rationale: ‚ÄúNeed-time / need-info‚Äù stalls are the single biggest reason a promising call ends in Process-Paused.\n",
      "   Description: Ship a ‚ÄúDeferred-Close Workflow.‚Äù\n",
      "1. In-Call Capture: When the agent marks a data field as ‚Äúpending,‚Äù the bot automatically generates a personalised secure link (SMS/e-mail) that lets the customer upload VIN, licence photo, banking info, etc. from their phone.\n",
      "2. Auto-Reminder Cadence: If the link is not completed, a lightly branded reminder is sent at +4 hrs and +24 hrs. Customers who finish the form are returned to the original agent‚Äôs queue.\n",
      "3. Visibility: The agent desktop shows real-time completion status so reps know exactly when to re-engage.\n",
      "4. KPI: Target a 35 % reduction in paused deals caused by missing information within 60 days.\n",
      "   Evidence: 47 % of the paused calls contain an explicit customer statement such as ‚ÄúI‚Äôll need to look that up / ask my son / wait until Friday‚Äù vs. only 6 % of successful closes.\n",
      "The classifier feature set corroborates this:\n",
      "‚Äì ‚ÄúCustomer explicitly says they need time to think/consult‚Äù (SSE = 0.0094)\n",
      "‚Äì ‚ÄúAgent stated finalizing quote depends on receiving additional info‚Äù (SSE = 0.0076)\n",
      "‚Äì ‚ÄúMissing underwriting data (VIN, DL#, mileage, etc.)‚Äù (SSE = 0.0094)\n",
      "Qualitative: Conv-20, 21, 24, 25, 28 all end with the customer promising to ‚Äúget the VIN / talk to spouse / wait for paperwork,‚Äù after which the agent simply emails a quote and hopes for the best.\n",
      "Business impact: 18-22 % of otherwise qualified prospects drift away; average $310 CAC increases to $470 when a second outreach cycle is required.\n",
      "\n",
      "2. Recommendation 2\n",
      "   Rationale: Decision maker often not on the line.\n",
      "   Description: Add ‚ÄúDecision-Maker Check & Transfer.‚Äù\n",
      "‚Ä¢ Within the first 60 seconds the script asks: ‚ÄúWill the person who makes the final decision be available to join us now?‚Äù\n",
      "‚Ä¢ If ‚ÄòNo‚Äô, agent triggers a one-click calendar module that texts a scheduling link (or instant three-way dial-out) to the decision maker. The CRM locks the lead until that joint meeting occurs.\n",
      "‚Ä¢ Agents are scored on usage; calls routed back if the step is skipped. Expected lift: +9 pp close rate on multi-party households.\n",
      "   Evidence: Feature ‚ÄúPrimary decision maker on call = no/unknown‚Äù has high lift (SSE = 0.0190). In 41 % of paused calls the customer says ‚Äúmy wife handles that‚Äù or ‚Äúmy daughter knows the details.‚Äù\n",
      "Example Conv-16, 20, 31. Agent continues a long qualifying script although purchase authority is absent, burning 10-12 minutes and aggravating the caller.\n",
      "Lost opportunity: When the policyholder is not present, the close-rate falls from 23 % to 4 %.\n",
      "\n",
      "3. Recommendation 3\n",
      "   Rationale: Warm-transfer IVR mazes kill momentum.\n",
      "   Description: Deploy Real-Time Quote Aggregator & Virtual Hold.\n",
      "‚Ä¢ Integrate a carrier API hub so that the initial agent can present at least one firm bindable quote without leaving the call.\n",
      "‚Ä¢ If carrier still requires a live transfer, use ‚Äúvirtual queuing‚Äù (carrier calls the prospect back) and let the agent set expectations (‚ÄúYou‚Äôll get a call from 555-1212 within 15 minutes‚Äù) instead of placing the customer on hold.\n",
      "‚Ä¢ Pilot with the top three volume carriers; measure drop-offs and handle-time. Goal: cut failed transfer rate by 50 %.\n",
      "   Evidence: ‚ÄúResult of carrier transfer attempt‚Äù (SSE = 0.0139) highly predictive: 62 % of paused outcomes follow a ‚Äúno-agent-available‚Äù or extended IVR hold.\n",
      "In Conv-14, 17, 20, customers wait 6-10 minutes listening to IVR prompts before giving up.\n",
      "Each failed transfer costs ~$14 in toll and rep salary, plus customer frustration.\n",
      "\n",
      "4. Recommendation 4\n",
      "   Rationale: Follow-up commitments are vague, and customers forget.\n",
      "   Description: Mandate Dated Call-Backs & Micro-Commitments.\n",
      "‚Ä¢ Agent UX: before ending a call without a sale, rep must enter a date/time checkbox. The customer then receives an iCal / Google Calendar invite.\n",
      "‚Ä¢ Script enhancement: reinforce a micro-commitment (‚ÄúCan I call you Friday at 9 AM after you‚Äôve reviewed the quote?‚Äù).\n",
      "‚Ä¢ CRM automatically re-dials at that time; no manual task creation. Target: raise follow-up contact rate from 27 % ‚Üí 60 %.\n",
      "   Evidence: ‚ÄúWas a follow-up action scheduled (Y/N)‚Äù (SSE = 0.0119) and ‚ÄúSpecific date/time given‚Äù (SSE = 0.0052) separate buys from pauses. Only 18 % of paused calls include an exact follow-up time, vs. 63 % of successful closes.\n",
      "Conv-26, 27, 30: agent says ‚ÄúI‚Äôll email you and call sometime next week,‚Äù no exact slot, lead goes cold.\n",
      "\n",
      "5. Recommendation 5\n",
      "   Rationale: Price framing & savings articulation are weak.\n",
      "   Description: Savings Calculator & Visual Aid.\n",
      "‚Ä¢ Auto-populates current premium (agent inputs) and juxtaposes proposed premium, displaying annual and monthly delta.\n",
      "‚Ä¢ Agent is prompted to verbalise: ‚ÄúThat‚Äôs a savings of $312 a year, or $26 each month.‚Äù\n",
      "‚Ä¢ Provide optional SMS graphic showing the side-by-side so the customer can discuss with family. Expected outcome: 15-18 % uplift in same-call conversions.\n",
      "   Evidence: Feature ‚ÄúCustomer objection = price_high‚Äù ranks #1 (SSE = 0.0196). In paused calls agents either do not present a concrete savings figure (Conv-22, 23) or quote a price without context (Conv-28).\n",
      "When reps quantified savings ‚â• $150/yr, acceptance occurred 2.4√ó more often; when they did not, 75 % asked for time to think.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## 11. Visualize Results with Interactive Dashboard\n",
    "\n",
    "Agentune Analyze includes a utility to generate an interactive HTML dashboard for exploring analysis results. This is a convenience to help visualize our outputs so you can later on use them in your application."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T18:22:20.490390Z",
     "start_time": "2025-11-10T18:22:20.472585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils.generate_analyze_dashboard import create_dashboard\n",
    "\n",
    "# Generate the dashboard\n",
    "dashboard_path = create_dashboard(\n",
    "    results=results,\n",
    "    output_file='analysis_dashboard.html',\n",
    "    title='Auto Insurance Conversation Analysis Results'\n",
    ")\n",
    "\n",
    "print(f'‚úì Dashboard generated: {dashboard_path}')\n",
    "print('\\nTo view the dashboard, open it in your browser')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Dashboard generated: analysis_dashboard.html\n",
      "\n",
      "To view the dashboard, open it in your browser\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What You'll See in the Dashboard\n",
    "\n",
    "The interactive dashboard includes:\n",
    "- **Target Distribution Chart**: Visual breakdown of outcome classes (desired outcome highlighted with gold border)\n",
    "- **Feature Performance Ranking**: Features sorted by R¬≤ (coefficient of determination)\n",
    "- **Sortable Feature Table**: Detailed statistics for all features\n",
    "- **Interactive Feature Comparison Tool**: Select multiple features to compare side-by-side\n",
    "- **Detailed Statistics**: Click any feature row to expand and see:\n",
    "  - R¬≤ score (variance explained)\n",
    "  - Distribution statistics (mean, std, missing values, unique categories)\n",
    "  - Relationship statistics (lift matrix, class distributions)\n",
    "  - For numeric features: histogram visualization\n",
    "\n",
    "**Note**: The R¬≤ (R-squared) metric shows what percentage of variance in the target outcome is explained by each feature. Values range from 0 (no predictive power) to 1 (perfect prediction). Higher values indicate stronger predictive features.\n",
    "\n",
    "See example below:\n",
    "\n",
    "![Analysis Results Dashboard](https://raw.githubusercontent.com/SparkBeyond/aoa/getting-started-guide/agentune-analyze/examples/screenshots/analysis_results_dashboard_screenshot.png)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## 12. Cleanup\n",
    "\n",
    "Let's clean up the resources we've been using."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T18:22:20.512800Z",
     "start_time": "2025-11-10T18:22:20.500780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Clean up resources: closes database connections, deletes temporary files, and frees memory\n",
    "await ctx.aclose()\n",
    "\n",
    "print('‚úì Resources cleaned up')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Resources cleaned up\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Best Practice: Context Manager\n",
    "\n",
    "For production code, it's recommended to use the context manager pattern, which automatically handles cleanup:\n",
    "\n",
    "```python\n",
    "async with await RunContext.create() as ctx:\n",
    "    # Load data\n",
    "    conversations_table = await ctx.data.from_csv('data.csv').copy_to_table('conversations')\n",
    "\n",
    "    # Split and search\n",
    "    split_data = await conversations_table.split(train_fraction=0.9)\n",
    "    problem = ProblemDescription(target_column='outcome', target_desired_outcome='buy')\n",
    "    results = await ctx.ops.analyze(problem, split_data)\n",
    "\n",
    "    # Use results...\n",
    "\n",
    "# Resources automatically cleaned up here when exiting the 'with' block\n",
    "```\n",
    "\n",
    "This ensures resources are always cleaned up, even if an error occurs. However, for interactive notebook exploration, the explicit `create()` and `close()` pattern shown in this tutorial is often more convenient."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this tutorial, you learned how to:\n",
    "\n",
    "* Load multi-table conversation data\n",
    "* Create a RunContext for managing resources\n",
    "* Split data for feature generation and evaluation\n",
    "* Run analysis on conversations\n",
    "* Explore discovered features and their predictive value\n",
    "* Generate actionable recommendations\n",
    "* Visualize results with an interactive dashboard\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "More tutorials coming soon!\n",
    "\n",
    "For detailed information, see the [Architecture Guide](../docs/).\n",
    "\n",
    "## Questions?\n",
    "\n",
    "Open an issue on GitHub or contact the maintainers. See the [main README](../README.md) for details.\n",
    "\n",
    "---\n",
    "\n",
    "**Tutorial complete!** üéâ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
