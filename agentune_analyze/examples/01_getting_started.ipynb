{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Agentune Analyze\n",
    "\n",
    "Welcome to Agentune Analyze! This tutorial will walk you through the fundamentals of using the library to analyze conversation data and generate insights.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- How to load multi-table conversation data\n",
    "- Running analysis on conversations\n",
    "- Exploring discovered features and their predictive value\n",
    "- Generating action recommendations from conversation patterns\n",
    "- Properly managing resources with RunContext\n",
    "\n",
    "**Estimated time**: 10-15 minutes\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Python >=3.12\n",
    "- Agentune Analyze installed (`pip install agentune-analyze`)\n",
    "- Jupyter Notebook installed (`pip install jupyter`)\n",
    "- OpenAI API key ([get one here](https://platform.openai.com/api-keys))\n",
    "\n",
    "**Note**: The sample data attached to this notebook is provided strictly for research and AI model development. Commercial use, resale, or redistribution is prohibited.\n",
    "**Note for Mac users**: If you encounter errors related to lightgbm, you may need to install OpenMP first: `brew install libomp`. See the [LightGBM macOS installation guide](https://lightgbm.readthedocs.io/en/latest/Installation-Guide.html) for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Setup and Imports\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:29:26.405891Z",
     "start_time": "2025-11-12T13:29:22.312558Z"
    }
   },
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "# Agentune Analyze imports\n",
    "from agentune.analyze.api.base import RunContext\n",
    "from agentune.analyze.feature.problem import ProblemDescription"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:29:26.417385Z",
     "start_time": "2025-11-12T13:29:26.413749Z"
    }
   },
   "source": [
    "# Recommended: Set the environment variable before starting Jupyter\n",
    "# export OPENAI_API_KEY=\"your-api-key-here\"\n",
    "\n",
    "# Alternative: Set it in the notebook (not recommended for production)\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"\n",
    "\n",
    "# Verify it's set\n",
    "if 'OPENAI_API_KEY' not in os.environ:\n",
    "    raise ValueError('Please set OPENAI_API_KEY environment variable')\n",
    "\n",
    "print('âœ“ Environment configured')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Environment configured\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Load Sample Data\n",
    "\n",
    "We'll work with auto insurance customer service conversations. The dataset consists of two tables:\n",
    "- **Conversations table** (conversations.csv): One row per conversation with outcome and duration\n",
    "- **Messages table** (messages.csv): Individual message turns within each conversation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:29:26.451540Z",
     "start_time": "2025-11-12T13:29:26.430733Z"
    }
   },
   "source": [
    "# Define data paths\n",
    "data_dir = Path('data')\n",
    "conversations_path = data_dir / 'conversations.csv'\n",
    "messages_path = data_dir / 'messages.csv'\n",
    "\n",
    "# Load data using Polars\n",
    "conversations_df = pl.read_csv(conversations_path)\n",
    "messages_df = pl.read_csv(messages_path)\n",
    "\n",
    "print(f'Loaded {len(conversations_df)} conversations')\n",
    "print(f'Loaded {len(messages_df)} message turns')\n",
    "print(f'\\nConversations columns: {conversations_df.columns}')\n",
    "print(f'Messages columns: {messages_df.columns}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 101 conversations\n",
      "Loaded 16823 message turns\n",
      "\n",
      "Conversations columns: ['conversation_id', 'outcome', 'duration_seconds']\n",
      "Messages columns: ['conversation_id', 'timestamp', 'message', 'author']\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:29:26.471802Z",
     "start_time": "2025-11-12T13:29:26.466091Z"
    }
   },
   "source": [
    "# Show outcome distribution\n",
    "print('Outcome distribution:')\n",
    "print(conversations_df.group_by('outcome').agg(pl.len()).sort('len', descending=True))\n",
    "\n",
    "print(f'\\nTotal conversations: {len(conversations_df)}')\n",
    "print(f'Total messages: {len(messages_df)}')\n",
    "print(f'Average messages per conversation: {len(messages_df) / len(conversations_df):.1f}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome distribution:\n",
      "shape: (6, 2)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”\n",
      "â”‚ outcome                         â”† len â”‚\n",
      "â”‚ ---                             â”† --- â”‚\n",
      "â”‚ str                             â”† u32 â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•¡\n",
      "â”‚ customer not interested         â”† 32  â”‚\n",
      "â”‚ process paused - customer needâ€¦ â”† 28  â”‚\n",
      "â”‚ process paused - customer needâ€¦ â”† 17  â”‚\n",
      "â”‚ customer objections not handleâ€¦ â”† 12  â”‚\n",
      "â”‚ no quote - ineligible customer  â”† 11  â”‚\n",
      "â”‚ buy                             â”† 1   â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "Total conversations: 101\n",
      "Total messages: 16823\n",
      "Average messages per conversation: 166.6\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Create RunContext\n",
    "\n",
    "The `RunContext` is your main entry point to Agentune Analyze. It manages all resources including database connections, HTTP clients, and LLM instances."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:29:27.194625Z",
     "start_time": "2025-11-12T13:29:26.498577Z"
    }
   },
   "source": [
    "# Create context\n",
    "ctx = await RunContext.create()\n",
    "\n",
    "print('âœ“ RunContext created')\n",
    "print('  - Database connection available')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ RunContext created\n",
      "  - Database connection available\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The RunContext will be used throughout the tutorial. Remember to close it when you're done (we'll show this at the end)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Load Data into DuckDB\n",
    "\n",
    "Now we'll load our Polars DataFrames into DuckDB tables, which Agentune Analyze uses for efficient data processing."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:29:27.259660Z",
     "start_time": "2025-11-12T13:29:27.208793Z"
    }
   },
   "source": [
    "# Load conversations table (main table: one row per conversation)\n",
    "conversations_table = await ctx.data.from_csv(conversations_path).copy_to_table('conversations')\n",
    "\n",
    "print(f'âœ“ Loaded conversations table: {conversations_table.name}')\n",
    "print(f'  Schema: {conversations_table.schema}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Loaded conversations table: \"memory\".\"main\".\"conversations\"\n",
      "  Schema: Schema(cols=(Field(name='conversation_id', dtype=SimpleDtype(name='str', duckdb_type=VARCHAR, polars_type=String)), Field(name='outcome', dtype=SimpleDtype(name='str', duckdb_type=VARCHAR, polars_type=String)), Field(name='duration_seconds', dtype=SimpleDtype(name='float64', duckdb_type=DOUBLE, polars_type=Float64))))\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:29:27.441831Z",
     "start_time": "2025-11-12T13:29:27.273339Z"
    }
   },
   "source": [
    "# Load messages table\n",
    "messages_table = await ctx.data.from_csv(messages_path).copy_to_table('messages')\n",
    "\n",
    "print(f'âœ“ Loaded messages table: {messages_table.name}')\n",
    "print(f'  Schema: {messages_table.schema}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Loaded messages table: \"memory\".\"main\".\"messages\"\n",
      "  Schema: Schema(cols=(Field(name='conversation_id', dtype=SimpleDtype(name='str', duckdb_type=VARCHAR, polars_type=String)), Field(name='timestamp', dtype=SimpleDtype(name='timestamp', duckdb_type=TIMESTAMP_MS, polars_type=Datetime(time_unit='ms', time_zone=None))), Field(name='message', dtype=SimpleDtype(name='str', duckdb_type=VARCHAR, polars_type=String)), Field(name='author', dtype=SimpleDtype(name='str', duckdb_type=VARCHAR, polars_type=String))))\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Define Table Relationships\n",
    "\n",
    "Now that both tables are loaded, we need to tell Agentune Analyze how they relate to each other for conversation analysis."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:29:27.459085Z",
     "start_time": "2025-11-12T13:29:27.455178Z"
    }
   },
   "source": [
    "# Define how the messages table relates to conversations\n",
    "join_strategy = messages_table.join_strategy.conversation(\n",
    "    name='messages',\n",
    "    main_table_key_col='conversation_id',\n",
    "    key_col='conversation_id',\n",
    "    timestamp_col='timestamp',\n",
    "    role_col='author',\n",
    "    content_col='message'\n",
    ")\n",
    "\n",
    "print('âœ“ Join strategy defined for multi-turn conversations')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Join strategy defined for multi-turn conversations\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Split Data\n",
    "\n",
    "Agentune Analyze splits your data into subsets for feature generation and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:29:27.488161Z",
     "start_time": "2025-11-12T13:29:27.472558Z"
    }
   },
   "source": [
    "# Split the conversations table (main table)\n",
    "split_data = await conversations_table.split(train_fraction=0.9)\n",
    "\n",
    "print('âœ“ Data split complete')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Data split complete\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The data is split into training (90%) and test (10%) subsets for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Define the Problem\n",
    "\n",
    "Tell Agentune Analyze what you're trying to predict. In our case, we want to predict the conversation outcome."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:29:27.500703Z",
     "start_time": "2025-11-12T13:29:27.497282Z"
    }
   },
   "source": [
    "# Define the prediction problem\n",
    "# Note: target_desired_outcome must exactly match a value from the outcome column\n",
    "# (see the outcome distribution shown in section 2 above)\n",
    "problem = ProblemDescription(\n",
    "    target_column='outcome',\n",
    "    problem_type='classification',\n",
    "    target_desired_outcome='process paused - customer needs to consider the offer',  # The outcome we want to optimize for\n",
    "    name='Customer Service Conversation Outcome Prediction',\n",
    "    description='Analyze the outcome of auto insurance customer service conversations, and suggest improvements for increasing insurance sales',\n",
    "    target_description='The final outcome of the conversation (buy, not interested, needs more info, etc.)'\n",
    ")\n",
    "\n",
    "print('âœ“ Problem defined')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Problem defined\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Run Analysis\n",
    "\n",
    "Now comes the exciting part! We'll run analysis, which will:\n",
    "1. Generate candidate features from conversation analysis\n",
    "2. Evaluate each feature's predictive power\n",
    "3. Select the most valuable features"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:36:56.765563Z",
     "start_time": "2025-11-12T13:29:27.511856Z"
    }
   },
   "source": [
    "# Run analysis!\n",
    "# This will take a few minutes to analyze conversation patterns\n",
    "\n",
    "print('Starting analysis...')\n",
    "print('This may take 5-10 minutes to analyze conversation patterns...')\n",
    "\n",
    "results = await ctx.ops.analyze(\n",
    "    problem_description=problem,\n",
    "    main_input=split_data,\n",
    "    secondary_tables=[messages_table],\n",
    "    join_strategies=[join_strategy]\n",
    ")\n",
    "\n",
    "print('\\nâœ“ Analysis complete!')\n",
    "print(f'  Discovered {len(results.features)} features')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis...\n",
      "This may take 5-10 minutes to analyze conversation patterns...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query \"monthly_premium_quoted\" has 52.63% empty values (>50.00%), skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Analysis complete!\n",
      "  Discovered 49 features\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Explore the Results\n",
    "\n",
    "Let's examine what features were discovered and how predictive they are."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:36:57.383737Z",
     "start_time": "2025-11-12T13:36:57.379099Z"
    }
   },
   "source": [
    "# Show discovered features\n",
    "print('Top 5 Discovered Features:\\n')\n",
    "for i, feature_with_stats in enumerate(results.features_with_train_stats[:5], 1):\n",
    "    feature = feature_with_stats.feature\n",
    "    stats = feature_with_stats.stats\n",
    "\n",
    "    print(f'{i}. {feature.name}')\n",
    "    print(f'   Description: {feature.description}')\n",
    "    print(f'   Type: {feature.dtype}')\n",
    "    print(f'   RÂ²: {stats.relationship.r_squared:.4f}')\n",
    "    print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Discovered Features:\n",
      "\n",
      "1. mail_me_then_decide\n",
      "   Description: Did the customer say they would decide after reviewing mailed/emailed documents? (Y / N)\n",
      "   Type: bool\n",
      "   RÂ²: 0.0701\n",
      "\n",
      "2. follow_up_method\n",
      "   Description: If follow-up scheduled, what method was agreed? (agent_call / customer_call / text / email / unspecified / none)\n",
      "   Type: Enum[text, none, email, agent_call, customer_call, callback, mail, _other_]\n",
      "   RÂ²: 0.0746\n",
      "\n",
      "3. rep_unavailable\n",
      "   Description: Did the agent explicitly state that no licensed representative was available to take the call at that moment? (Y / N)\n",
      "   Type: bool\n",
      "   RÂ²: 0.0753\n",
      "\n",
      "4. follow_up_scheduled\n",
      "   Description: Was an explicit follow-up (call, text, email, or callback) scheduled or proposed? (Y / N)\n",
      "   Type: bool\n",
      "   RÂ²: 0.0500\n",
      "\n",
      "5. quote_delivery_requested\n",
      "   Description: Did the customer ask to receive the quote in writing (email, text link or postal mail) before deciding? (Y / N)\n",
      "   Type: bool\n",
      "   RÂ²: 0.0456\n",
      "\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Generate Action Recommendations\n",
    "\n",
    "Based on the conversation patterns, generate actionable recommendations for improving outcomes."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:38:52.206027Z",
     "start_time": "2025-11-12T13:36:57.389147Z"
    }
   },
   "source": [
    "# Generate recommendations\n",
    "print('Generating action recommendations...')\n",
    "\n",
    "recommendations = await ctx.ops.recommend_conversation_actions(\n",
    "    analyze_input=split_data,\n",
    "    analyze_results=results\n",
    ")\n",
    "\n",
    "print('\\nâœ“ Generated recommendations' if recommendations else '\\nâœ“ No recommendations generated')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating action recommendations...\n",
      "\n",
      "âœ“ Generated recommendations\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:38:52.831206Z",
     "start_time": "2025-11-12T13:38:52.827408Z"
    }
   },
   "source": [
    "# Display top 3 recommendations\n",
    "print('\\nTop 3 Recommendations:\\n')\n",
    "for i, rec in enumerate(recommendations.recommendations[:3], 1):\n",
    "    print(f'{i}. {rec.title}')\n",
    "    print(f'   Rationale: {rec.rationale}')\n",
    "    print(f'   Description: {rec.description}')\n",
    "    print(f'   Evidence: {rec.evidence}')\n",
    "    print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 3 Recommendations:\n",
      "\n",
      "1. Instant Written Quote & Self-Serve Review Link\n",
      "   Rationale: â€¢ Customers fear committing on a live call; they need time to compare or share with family.\n",
      "â€¢ Agents promise â€œWeâ€™ll e-mail itâ€ but (a) have no one-click way to generate a concise written quote, (b) forget to send it, or (c) send a generic brochure that doesnâ€™t show the exact premium.\n",
      "â€¢ Typical delay: 2-8 hours â†’ customer churns, forgets, or shops elsewhere.\n",
      "â€¢ Every 10 % uptick in â€œwritten-quote firstâ€ customers costs â‰ˆ $140K / year in lost premium (internal win-rate data: only 11 % of these return to bind).\n",
      "   Description: Build â€œQuote-Snapshotâ€ inside the agent console:\n",
      "1. One-click PDF / HTML with carrier, coverage stack, deductible, first-month and monthly cost, discount list, and a 7-day expiration badge.\n",
      "2. Auto-send via the customerâ€™s chosen channel (e-mail or SMS link).\n",
      "3. Embed a large â€œContinue & Buyâ€ button that opens a pre-filled checkout flow or schedules a licensed closer call.\n",
      "4. Track open / click / time-on-page events and push them to the dialer CRM so the agent is alerted when the prospect is â€œwarmâ€ again.\n",
      "5. Add A/B expiry banners (â€œLock this rate by Monday 5 PMâ€) to prompt faster action.\n",
      "   Evidence: When customers ask to â€œreview the numbers firstâ€ the process almost always stalls.\n",
      "Feature #1 (â€œCustomer asked to receive quote in writingâ€) is the single most predictive driver of Process-Paused (SSE = 0.0102) and appears in 62 % of the paused calls vs. only 14 % of converted calls.\n",
      "\n",
      "2. Mandatory Follow-Up Appointment Before You Hang Up\n",
      "   Rationale: â€¢ Without a next step, prospects vanish into voicemail hell.\n",
      "â€¢ Paused deals that lacked a calendar booking closed at 7 %; those with one closed at 29 %.\n",
      "â€¢ Agent forgetfulness (â€œIâ€™ll give you a call tomorrow sometimeâ€) = no accountability.\n",
      "   Description: 1. Force a â€œFollow-up wizardâ€ when call outcome is set to â€œQuote E-mailed / Needs to Think.â€\n",
      "2. Wizard shows prospectâ€™s local time, offers three quick-pick slots (24h, 48h, Saturday AM) and writes the chosen slot to the CRM plus an .ics calendar invite for both parties.\n",
      "3. If customer refuses to choose, agent must log a reason code; the system schedules an automation text reminder anyway (â€œJust checkingâ€”any questions before we call Thursday at 3 PM?â€).\n",
      "4. Failures to place the booked call are surfaced on the team dashboard and count toward QA score.\n",
      "   Evidence: Only 28 % of Process-Paused calls have a date-and-time follow-up vs. 71 % of successful conversions.\n",
      "Feature #9 (â€œCustomer asked agent to call back at a specific timeâ€) and Feature #12 (â€œAgent scheduled a concrete follow-upâ€) jointly cut SSE by 0.0146, but agents often skip the step.\n",
      "\n",
      "3. â€œLicensed Rep Unavailableâ€ Escape Hatch\n",
      "   Rationale: â€¢ Prospect has already invested time; another queue erodes trust.\n",
      "â€¢ Competitors answer on the first ring; we look understaffed.\n",
      "â€¢ Backend staffing peaks donâ€™t align with marketing dial blasts.\n",
      "   Description: 1. Build a small â€œwarm-queue callbackâ€ micro-service: if no closer is free within 30 seconds, the IVR tells the prospect â€œWeâ€™ll call you back in 15 minutes sharp,â€ keeps their place in line, and books that into the closerâ€™s dialer.\n",
      "2. Display the real-time licensed-rep load in the screener UI; if red, they switch to â€œinformation-gather-onlyâ€ script, send Quote-Snapshot (Rec #1) and schedule the follow-up (Rec #2) instead of parking the caller on hold.\n",
      "3. Staffing: move one licensed rep per pod to â€œrapid-responseâ€ status during dialer surges; enforce SLA < 45 sec.\n",
      "   Evidence: In 17 % of paused calls the screener admits â€œNo licensed agent is free right nowâ€â€”Feature #3 (SSE = 0.0137). Hold-times of 4â€“12 minutes kill momentum; twice as many customers bail vs. when transfer is instantaneous.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 11. Visualize Results with Interactive Dashboards\n\nAgentune Analyze includes utilities to generate interactive HTML dashboards for exploring your results. These are convenience tools to help visualize outputs so you can integrate them into your applications.\n\nWe'll create two dashboards:\n1. **Analysis Dashboard** - Explore discovered features and their statistics\n2. **Recommendations Dashboard** - Review actionable recommendations"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:38:52.860924Z",
     "start_time": "2025-11-12T13:38:52.842311Z"
    }
   },
   "source": "from utils import create_analyze_dashboard\n\n# Generate the dashboard\ndashboard_path = create_analyze_dashboard(\n    results=results,\n    output_file='analysis_dashboard.html',\n    title='Auto Insurance Conversation Analysis Results'\n)\n\nprint(f'âœ“ Dashboard generated: {dashboard_path}')\nprint('\\nTo view the dashboard, open it in your browser')",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Dashboard generated: analysis_dashboard.html\n",
      "\n",
      "To view the dashboard, open it in your browser\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": "### Analysis Dashboard\n\nThe interactive analysis dashboard includes:\n- **Target Distribution Chart**: Visual breakdown of outcome classes (desired outcome highlighted with gold border)\n- **Feature Performance Ranking**: Features sorted by RÂ² (coefficient of determination)\n- **Sortable Feature Table**: Detailed statistics for all features\n- **Interactive Feature Comparison Tool**: Select multiple features to compare side-by-side\n- **Detailed Statistics**: Click any feature row to expand and see:\n  - RÂ² score (variance explained)\n  - Distribution statistics (mean, std, missing values, unique categories)\n  - Relationship statistics (lift matrix, class distributions)\n  - For numeric features: histogram visualization\n\n**Note**: The RÂ² (R-squared) metric shows what percentage of variance in the target outcome is explained by each feature. Values range from 0 (no predictive power) to 1 (perfect prediction). Higher values indicate stronger predictive features.\n\n**Example dashboard:**\n\n![Analysis Results Dashboard](https://raw.githubusercontent.com/SparkBeyond/agentune/main/agentune_analyze/examples/screenshots/analysis_results_dashboard_screenshot.png)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:38:52.875064Z",
     "start_time": "2025-11-12T13:38:52.870859Z"
    }
   },
   "source": "from utils import create_recommendations_dashboard\n\n# Generate dashboard\ndashboard_path = create_recommendations_dashboard(\n    report=recommendations,\n    output_file='recommendations_dashboard.html',\n    title='Auto Insurance Action Recommendations'\n)\n\nprint(f'âœ“ Dashboard generated: {dashboard_path}')\nprint('\\nTo view the dashboard, open it in your browser')",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Dashboard generated: recommendations_dashboard.html\n",
      "\n",
      "To view the dashboard, open it in your browser\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Recommendations Dashboard\n",
    "\n",
    "The recommendations dashboard provides:\n",
    "- **Structured Recommendations**: Each recommendation includes title, rationale, detailed description, and supporting evidence\n",
    "- **Evidence Links**: Direct references to features and supporting conversations\n",
    "- **Implementation Details**: Specific, actionable steps for each recommendation\n",
    "\n",
    "**Note**: You can also access the full text report programmatically using `recommendations.raw_report` if needed for further processing.\n",
    "\n",
    "**Example dashboard:**\n",
    "\n",
    "![Recommendations Dashboard](https://raw.githubusercontent.com/SparkBeyond/agentune/main/agentune_analyze/examples/screenshots/recommendation_results_dashboard_screenshot.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12. Cleanup\n",
    "\n",
    "Let's clean up the resources we've been using."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T13:38:52.905248Z",
     "start_time": "2025-11-12T13:38:52.893409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Clean up resources: closes database connections, deletes temporary files, and frees memory\n",
    "await ctx.aclose()\n",
    "\n",
    "print('âœ“ Resources cleaned up')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Resources cleaned up\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Practice: Context Manager\n",
    "\n",
    "For production code, it's recommended to use the context manager pattern, which automatically handles cleanup:\n",
    "\n",
    "```python\n",
    "async with await RunContext.create() as ctx:\n",
    "    # Load data\n",
    "    conversations_table = await ctx.data.from_csv('data.csv').copy_to_table('conversations')\n",
    "\n",
    "    # Split and search\n",
    "    split_data = await conversations_table.split(train_fraction=0.9)\n",
    "    problem = ProblemDescription(target_column='outcome', target_desired_outcome='buy')\n",
    "    results = await ctx.ops.analyze(problem, split_data)\n",
    "\n",
    "    # Use results...\n",
    "\n",
    "# Resources automatically cleaned up here when exiting the 'with' block\n",
    "```\n",
    "\n",
    "This ensures resources are always cleaned up, even if an error occurs. However, for interactive notebook exploration, the explicit `create()` and `close()` pattern shown in this tutorial is often more convenient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## Summary\n\nIn this tutorial, you learned how to:\n\n* Load multi-table conversation data\n* Create a RunContext for managing resources\n* Split data for feature generation and evaluation\n* Run analysis on conversations\n* Explore discovered features and their predictive value\n* Generate actionable recommendations\n* Visualize results with an interactive dashboard\n\n## Next Steps\n\nFor advanced usage examples including customizing components, using different models, and configuring LLM caching, see [advanced_examples.md](advanced_examples.md).\n\nFor detailed information on architecture and design principles, see the [Architecture Guide](../docs/).\n\n## Questions?\n\nOpen an issue on GitHub or contact the maintainers. See the [main README](../README.md) for details.\n\n---\n\n**Tutorial complete!** ğŸ‰"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
