{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persistent Storage and Production Features with Agentune Simulate\n",
    "\n",
    "  This notebook builds on the basic concepts from `getting_started.ipynb` to\n",
    "  demonstrate production-ready features of Agentune Simulate.\n",
    "\n",
    "  **Prerequisites**: Complete `getting_started.ipynb` first to understand the basics\n",
    "  of conversation simulation.\n",
    "\n",
    "  ## What you'll learn:\n",
    "  - Set up persistent vector storage with Chroma for production use\n",
    "  - Reuse vector stores across sessions to save time and resources\n",
    "  - Handle larger datasets efficiently with persistent storage\n",
    "  - Best practices for production deployments and scaling\n",
    "  - Advanced configuration options for real-world scenarios\n",
    "\n",
    "  ## Key Benefits of Persistent Storage:\n",
    "  - **Performance**: No need to rebuild vector stores each session\n",
    "  - **Scalability**: Handle thousands of conversations efficiently\n",
    "  - **Cost Efficiency**: Reduce embedding computation costs through reuse\n",
    "  - **Production Ready**: Suitable for deployment in production environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "First, install the required dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T14:03:27.619459Z",
     "start_time": "2025-07-23T14:03:23.931925Z"
    }
   },
   "source": [
    "!pip install -q langchain-chroma pandas\n",
    "!pip install -q agentune-simulate"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T14:03:29.772500Z",
     "start_time": "2025-07-23T14:03:27.775396Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "from agentune.simulate.models import Outcomes\n",
    "from agentune.simulate.rag import conversations_to_langchain_documents\n",
    "from agentune.simulate.simulation.session_builder import SimulationSessionBuilder\n",
    "\n",
    "# Import example utilities\n",
    "from utils import setup_logging_and_asyncio, load_conversations_from_csv, extract_outcomes_from_conversations"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setup and API Key Configuration\n",
    "\n",
    "This example uses OpenAI models, but any LangChain-compatible LLM can be supported. Configure your API key for the model provider you choose:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T14:03:38.533472Z",
     "start_time": "2025-07-23T14:03:29.782917Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "# Set up OpenAI API key\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "\n",
    "print(\"✓ API key configured\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ API key configured\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T14:03:38.581039Z",
     "start_time": "2025-07-23T14:03:38.577880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configure logging and asyncio for Jupyter\n",
    "setup_logging_and_asyncio()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Logging configured\n",
      "✓ Asyncio event loop configured for Jupyter\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Explore Sample Data\n",
    "\n",
    "**Important**: For any data format or source, you must convert your data to `Conversation` objects for the simulator to work.\n",
    "\n",
    "This example shows loading from CSV format:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T14:03:38.905803Z",
     "start_time": "2025-07-23T14:03:38.653397Z"
    }
   },
   "source": [
    "# load_conversations_from_csv is an example utility function that converts CSV data to Conversation objects\n",
    "# Example data is based on dhc2 dataset\n",
    "# You need to implement a similar function for your data format and schema\n",
    "conversations = load_conversations_from_csv(\"data/sample_conversations.csv\")\n",
    "\n",
    "print(f\"Loaded {len(conversations)} conversations\")\n",
    "print(f\"Sample conversation has {len(conversations[0].messages)} messages\")\n",
    "print(f\"First message: {conversations[0].messages[0].content[:100]}...\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 conversations\n",
      "Sample conversation has 6 messages\n",
      "First message: Last night, I waited in line for 2 hours in the business office, but because I only had a copy of my...\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T14:03:38.950116Z",
     "start_time": "2025-07-23T14:03:38.925006Z"
    }
   },
   "source": [
    "# Explore the data structure\n",
    "df = pd.read_csv(\"data/sample_conversations.csv\")\n",
    "print(\"Dataset overview:\")\n",
    "print(f\"- Total messages: {len(df)}\")\n",
    "print(f\"- Unique conversations: {df['conversation_id'].nunique()}\")\n",
    "print(f\"- Message distribution: {df['sender'].value_counts().to_dict()}\")\n",
    "print(f\"- Outcome distribution: {df['outcome_name'].value_counts().to_dict()}\")\n",
    "\n",
    "df.head()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset overview:\n",
      "- Total messages: 409\n",
      "- Unique conversations: 100\n",
      "- Message distribution: {'customer': 228, 'agent': 181}\n",
      "- Outcome distribution: {'resolved': 365, 'unresolved': 44}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  conversation_id    sender  \\\n",
       "0        conv_001  customer   \n",
       "1        conv_001     agent   \n",
       "2        conv_001  customer   \n",
       "3        conv_001     agent   \n",
       "4        conv_001  customer   \n",
       "\n",
       "                                             content  \\\n",
       "0  Last night, I waited in line for 2 hours in th...   \n",
       "1  We’re very sorry, I am the Guangdong Customer ...   \n",
       "2  How can consumers supervise you if you don't s...   \n",
       "3  We will continue to improve various services a...   \n",
       "4  Nonsense. China Telecom has failed to make pro...   \n",
       "\n",
       "                   timestamp outcome_name              outcome_description  \n",
       "0  2024-01-15T09:00:00+00:00     resolved  Issue was successfully resolved  \n",
       "1  2024-01-15T09:02:00+00:00     resolved  Issue was successfully resolved  \n",
       "2  2024-01-15T09:05:00+00:00     resolved  Issue was successfully resolved  \n",
       "3  2024-01-15T09:09:00+00:00     resolved  Issue was successfully resolved  \n",
       "4  2024-01-15T09:14:00+00:00     resolved  Issue was successfully resolved  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>sender</th>\n",
       "      <th>content</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>outcome_name</th>\n",
       "      <th>outcome_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>conv_001</td>\n",
       "      <td>customer</td>\n",
       "      <td>Last night, I waited in line for 2 hours in th...</td>\n",
       "      <td>2024-01-15T09:00:00+00:00</td>\n",
       "      <td>resolved</td>\n",
       "      <td>Issue was successfully resolved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>conv_001</td>\n",
       "      <td>agent</td>\n",
       "      <td>We’re very sorry, I am the Guangdong Customer ...</td>\n",
       "      <td>2024-01-15T09:02:00+00:00</td>\n",
       "      <td>resolved</td>\n",
       "      <td>Issue was successfully resolved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>conv_001</td>\n",
       "      <td>customer</td>\n",
       "      <td>How can consumers supervise you if you don't s...</td>\n",
       "      <td>2024-01-15T09:05:00+00:00</td>\n",
       "      <td>resolved</td>\n",
       "      <td>Issue was successfully resolved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>conv_001</td>\n",
       "      <td>agent</td>\n",
       "      <td>We will continue to improve various services a...</td>\n",
       "      <td>2024-01-15T09:09:00+00:00</td>\n",
       "      <td>resolved</td>\n",
       "      <td>Issue was successfully resolved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>conv_001</td>\n",
       "      <td>customer</td>\n",
       "      <td>Nonsense. China Telecom has failed to make pro...</td>\n",
       "      <td>2024-01-15T09:14:00+00:00</td>\n",
       "      <td>resolved</td>\n",
       "      <td>Issue was successfully resolved</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Outcomes for Simulation\n",
    "\n",
    "Extract unique outcomes that our simulation will try to achieve:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T14:03:38.999734Z",
     "start_time": "2025-07-23T14:03:38.995622Z"
    }
   },
   "source": [
    "# Extract unique outcomes from conversations\n",
    "# Alternatively, you can define outcomes manually if you know them in advance\n",
    "unique_outcomes = extract_outcomes_from_conversations(conversations)\n",
    "outcomes = Outcomes(outcomes=tuple(unique_outcomes))\n",
    "\n",
    "print(f\"Found {len(unique_outcomes)} unique outcomes:\")\n",
    "for outcome in unique_outcomes:\n",
    "    print(f\"- {outcome.name}: {outcome.description}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 unique outcomes:\n",
      "- resolved: Issue was successfully resolved\n",
      "- unresolved: Issue was not resolved\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: You can also define outcomes manually if you know them in advance, instead of extracting them from existing conversations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Models and Vector Store\n",
    "\n",
    "Chroma is a popular vector store for production use, allowing you to store vector data persistently and reuse it across sessions. Other LangChain-compatible vector stores can also be used.\n",
    "\n",
    "For production use, you'll want persistent vector storage. Here's how to use Chroma:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T14:03:39.310715Z",
     "start_time": "2025-07-23T14:03:39.044874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Setup models - OpenAI models work well, other LangChain-compatible models can also be used\n",
    "# Note: gpt-4o has been tested and performs best for realistic conversations\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o\", temperature=0.7)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Use all conversations for vector store training (simplified approach)\n",
    "# Advanced: you could split data to reserve some conversations for validation\n",
    "training_conversations = conversations\n",
    "print(f\"Using {len(training_conversations)} conversations for vector store training\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 100 conversations for vector store training\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T14:03:43.677868Z",
     "start_time": "2025-07-23T14:03:39.327150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create persistent Chroma vector store\n",
    "persist_directory = \"./chroma_db\"\n",
    "\n",
    "chroma_store = Chroma(\n",
    "    collection_name=\"conversation_examples\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "documents = conversations_to_langchain_documents(conversations)\n",
    "chroma_store.add_documents(documents)\n",
    "print(f\"✓ Added {len(documents)} documents to Chroma\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-23 17:03:39,346 - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Added 409 documents to Chroma\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Run Simulation"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T14:04:31.597482Z",
     "start_time": "2025-07-23T14:03:43.699526Z"
    }
   },
   "source": [
    "# Build session with Chroma vector store  \n",
    "chroma_session = SimulationSessionBuilder(\n",
    "    default_chat_model=chat_model,\n",
    "    outcomes=outcomes,\n",
    "    vector_store=chroma_store,\n",
    ").build()\n",
    "\n",
    "# Run simulation with Chroma\n",
    "base_conversations = conversations[:5]\n",
    "chroma_result = await chroma_session.run_simulation(real_conversations=base_conversations)\n",
    "\n",
    "print(\"✓ Chroma simulation completed!\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-23 17:03:43,702 - Starting intent extraction on 5 conversations\n",
      "2025-07-23 17:03:52,403 - Finished extracting original intents; generated 5 scenarios\n",
      "2025-07-23 17:03:52,404 - Starting conversation simulations (self.max_concurrent_conversations=20)\n",
      "2025-07-23 17:03:57,406 - Progress: 0/5 scenarios completed\n",
      "2025-07-23 17:04:07,408 - Progress: 2/5 scenarios completed\n",
      "2025-07-23 17:04:12,410 - Progress: 3/5 scenarios completed\n",
      "2025-07-23 17:04:22,413 - Progress: 5/5 scenarios completed\n",
      "2025-07-23 17:04:22,414 - Finished simulating conversations; simulated 5 conversations, with 0 failures\n",
      "2025-07-23 17:04:22,415 - Starting analysis of simulation results\n",
      "2025-07-23 17:04:31,594 - Finished analyzing results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Chroma simulation completed!\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T14:04:31.627201Z",
     "start_time": "2025-07-23T14:04:31.614360Z"
    }
   },
   "source": [
    "# Compare results and save\n",
    "print(\"=== CHROMA RESULTS ===\")\n",
    "print(chroma_result.generate_summary())\n",
    "\n",
    "# Save results to file using built-in method\n",
    "output_file = \"chroma_simulation_results.json\"\n",
    "chroma_result.save_to_file(output_file)\n",
    "print(f\"\\n✓ Results saved to {Path(output_file).resolve().relative_to(Path('../../').resolve())}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CHROMA RESULTS ===\n",
      "========================================\n",
      "SIMULATION RESULTS\n",
      "========================================\n",
      "Session name: Simulation Session\n",
      "Original conversations: 5\n",
      "Simulated conversations: 5\n",
      "\n",
      "Average messages per conversation:\n",
      "  Original: 4.4\n",
      "  Simulated: 2.8\n",
      "\n",
      "Outcome distribution comparison:\n",
      "Outcome              Original        Simulated      \n",
      "--------------------------------------------------\n",
      "resolved               4 (80.0%)     3 (60.0%)\n",
      "unresolved             1 (20.0%)     2 (40.0%)\n",
      "\n",
      "Sample conversation (4 messages):\n",
      "  1. customer: Last night, I waited in line for 2 hours in the business office, but because I only had a copy of my...\n",
      "  2. agent: I apologize for the inconvenience and frustration you've experienced with the cancellation process. ...\n",
      "  3. customer: I understand the need for the original ID and the set-top box now, but my issue is with the lack of ...\n",
      "  4. agent: I completely understand your frustration, and I apologize for the inconvenience this has caused. I w...\n",
      "========================================\n",
      "\n",
      "✓ Results saved to agentune_simulate/examples/chroma_simulation_results.json\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that you've completed a basic simulation:\n",
    "\n",
    "1. **Use your own data**: Load your own conversations as a list of `Conversation` objects and use them to set up the simulation. See this example for loading conversations from tabular data: [Loading Conversations Example](https://github.com/SparkBeyond/agentune/blob/main/agentune_simulate/examples/loading_conversations.ipynb).\n",
    "2. **Explore advanced features**: Check out the full documentation for more options caching of LLM responses, LLM failures handling, and more.\n",
    "\n",
    "### Resources:\n",
    "- [Full documentation](https://github.com/SparkBeyond/agentune/blob/main/agentune_simulate/README.md)\n",
    "- [Advanced LLM config](https://github.com/SparkBeyond/agentune/blob/main/agentune_simulate/docs/langchain.md)\n",
    "- [Complete examples](https://github.com/SparkBeyond/agentune/tree/main/agentune_simulate/examples)\n",
    "- [Streamlit web interface](https://github.com/SparkBeyond/agentune/blob/main/agentune_simulate/streamlit/README.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
