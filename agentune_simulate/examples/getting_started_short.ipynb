{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Getting Started with Agentune Simulate - Quick Start\n",
    "\n",
    "This notebook provides a streamlined introduction to the Agentune Simulate library. You'll learn to:\n",
    "\n",
    "- Load conversation data and extract outcomes\n",
    "- Set up RAG-based simulation with in-memory vector store\n",
    "- Run simulations and analyze results\n",
    "\n",
    "**Note**: This is a simplified version. For more detailed examples including persistent storage, see `getting_started.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "from agentune.simulate.models import Outcomes\n",
    "from agentune.simulate.rag import conversations_to_langchain_documents\n",
    "from agentune.simulate.simulation.session_builder import SimulationSessionBuilder\n",
    "from utils import setup_logging_and_asyncio, load_data_with_outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## API Key Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your OpenAI API key:  ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ API key configured\n"
     ]
    }
   ],
   "source": [
    "# Set up OpenAI API key\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "\n",
    "print(\"✓ API key configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Logging configured\n",
      "✓ Asyncio event loop configured for Jupyter\n"
     ]
    }
   ],
   "source": [
    "# Configure logging and asyncio for Jupyter\n",
    "setup_logging_and_asyncio()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Load Data and Extract Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading conversations from data/sample_conversations.csv...\n",
      "✓ Loaded 100 conversations\n",
      "✓ Sample conversation has 6 messages\n",
      "✓ Extracted 2 unique outcomes\n",
      "  - resolved: Issue was successfully resolved\n",
      "  - unresolved: Issue was not resolved\n"
     ]
    }
   ],
   "source": [
    "# Load conversations and extract outcomes in one step\n",
    "conversations, outcomes_tuple = load_data_with_outcomes(\"data/sample_conversations.csv\")\n",
    "outcomes = Outcomes(outcomes=outcomes_tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Create Models and Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created vector store with 409 documents\n"
     ]
    }
   ],
   "source": [
    "# Setup models\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o\", temperature=0.7)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Create in-memory vector store\n",
    "documents = conversations_to_langchain_documents(conversations)\n",
    "vector_store = InMemoryVectorStore.from_documents(documents, embeddings)\n",
    "\n",
    "print(f\"✓ Created vector store with {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Run Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 16:39:13,509 - Starting intent extraction on 5 conversations\n",
      "2025-07-16 16:39:17,966 - Finished extracting original intents; generated 5 scenarios\n",
      "2025-07-16 16:39:17,967 - Starting conversation simulations (self.max_concurrent_conversations=20)\n",
      "2025-07-16 16:39:22,968 - Progress: 0/5 scenarios completed\n",
      "2025-07-16 16:39:52,973 - Progress: 2/5 scenarios completed\n",
      "2025-07-16 16:39:57,975 - Progress: 4/5 scenarios completed\n",
      "2025-07-16 16:40:07,979 - Progress: 5/5 scenarios completed\n",
      "2025-07-16 16:40:07,980 - Finished simulating conversations; simulated 5 conversations, with 0 failures\n",
      "2025-07-16 16:40:07,980 - Starting analysis of simulation results\n",
      "2025-07-16 16:40:16,483 - Finished analyzing results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Simulation completed!\n"
     ]
    }
   ],
   "source": [
    "# Build and run simulation session\n",
    "session = SimulationSessionBuilder(\n",
    "    default_chat_model=chat_model,\n",
    "    outcomes=outcomes,\n",
    "    vector_store=vector_store,\n",
    "    max_messages=10\n",
    ").build()\n",
    "\n",
    "# Run simulation with first 5 conversations as starting points\n",
    "base_conversations = conversations[:5]\n",
    "result = await session.run_simulation(real_conversations=base_conversations)\n",
    "\n",
    "print(\"✓ Simulation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "SIMULATION RESULTS\n",
      "========================================\n",
      "Session name: Simulation Session\n",
      "Original conversations: 5\n",
      "Simulated conversations: 5\n",
      "\n",
      "Average messages per conversation:\n",
      "  Original: 4.4\n",
      "  Simulated: 10.0\n",
      "\n",
      "Outcome distribution comparison:\n",
      "Outcome              Original        Simulated      \n",
      "--------------------------------------------------\n",
      "resolved               4 (80.0%)     5 (100.0%)\n",
      "unresolved             1 (20.0%)     0 ( 0.0%)\n",
      "\n",
      "Sample conversation (10 messages):\n",
      "  1. customer: Last night, I waited in line for 2 hours in the business office, but because I only had a copy of my...\n",
      "  2. agent: I'm really sorry for the inconvenience you've experienced. To resolve this, please make sure to brin...\n",
      "  3. customer: This is absolutely ridiculous! How many more hoops do I need to jump through before I can cancel the...\n",
      "  4. agent: I'm really sorry for the frustration this has caused. I'll escalate your issue internally to ensure ...\n",
      "  ... and 6 more messages\n",
      "========================================\n",
      "\n",
      "✓ Results saved to simulation_results.json\n"
     ]
    }
   ],
   "source": [
    "# Display comprehensive results\n",
    "print(result.generate_summary())\n",
    "\n",
    "# Save results to file\n",
    "output_file = \"simulation_results.json\"\n",
    "result.save_to_file(output_file)\n",
    "print(f\"\\n✓ Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that you've completed a basic simulation:\n",
    "\n",
    "1. **Scale up**: Try with more conversations and longer interactions\n",
    "2. **Use your own data**: Convert your data to the CSV format shown in `data/sample_conversations.csv`\n",
    "3. **Advanced features**: See `getting_started.ipynb` for persistent storage with Chroma and more detailed explanations\n",
    "4. **Web interface**: Try the Streamlit app at `streamlit/app.py`\n",
    "\n",
    "### For your own data:\n",
    "Create a CSV with columns: `conversation_id`, `sender`, `content`, `timestamp`, `outcome_name`, `outcome_description`\n",
    "\n",
    "### Resources:\n",
    "- [Full documentation](../README.md)\n",
    "- [Complete examples](../examples/)\n",
    "- [Streamlit web interface](../streamlit/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
