{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Getting Started with Agentune Simulate - Quick Start\n\nThis notebook provides a streamlined introduction to the Agentune Simulate library. You'll learn to:\n\n- Load conversation data and extract outcomes\n- Set up RAG-based simulation with in-memory vector store\n- Run simulations and analyze results\n\n**Note**: This is a simplified version. For persistent storage and production features, see `persistent_storage_example.ipynb`.",
   "id": "3aa130e053c5c870"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ],
   "id": "32d0b932c40d0d53"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import os\nimport getpass\nfrom langchain_core.vectorstores import InMemoryVectorStore\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\n\nfrom agentune.simulate.models import Outcomes\nfrom agentune.simulate.rag import conversations_to_langchain_documents\nfrom agentune.simulate.simulation.session_builder import SimulationSessionBuilder\nfrom utils import setup_logging_and_asyncio, load_data_with_outcomes",
   "outputs": [],
   "execution_count": null,
   "id": "c1fe6389638ce085"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Key Configuration"
   ],
   "id": "41426b8206a7554e"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Set up OpenAI API key\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "\n",
    "print(\"✓ API key configured\")"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "4a632f7becb42474"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ],
   "id": "414e502fe67a8c4d"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Configure logging and asyncio for Jupyter\n",
    "setup_logging_and_asyncio()"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "5fe17526961bb40f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Extract Outcomes"
   ],
   "id": "cea5006945c174c3"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load conversations and extract outcomes in one step\n",
    "conversations, outcomes_tuple = load_data_with_outcomes(\"data/sample_conversations.csv\")\n",
    "outcomes = Outcomes(outcomes=outcomes_tuple)"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "8c62dc6da23b6029"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Models and Vector Store"
   ],
   "id": "662f0448c13a680f"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Setup models\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o\", temperature=0.7)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Create in-memory vector store\n",
    "documents = conversations_to_langchain_documents(conversations)\n",
    "vector_store = InMemoryVectorStore.from_documents(documents, embeddings)\n",
    "\n",
    "print(f\"✓ Created vector store with {len(documents)} documents\")"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "eadffcdd34883c4e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Simulation"
   ],
   "id": "5ee320d2f56cb4ad"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Build and run simulation session\n",
    "session = SimulationSessionBuilder(\n",
    "    default_chat_model=chat_model,\n",
    "    outcomes=outcomes,\n",
    "    vector_store=vector_store,\n",
    "    max_messages=10\n",
    ").build()\n",
    "\n",
    "# Run simulation with first 5 conversations as starting points\n",
    "base_conversations = conversations[:5]\n",
    "result = await session.run_simulation(real_conversations=base_conversations)\n",
    "\n",
    "print(\"✓ Simulation completed!\")"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "31a523c456684063"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Results"
   ],
   "id": "e8191ffd2235192b"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "print(result.generate_summary())",
   "outputs": [],
   "execution_count": null,
   "id": "39b6671b5a1c16da"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that you've completed a basic simulation:\n",
    "\n",
    "  1. **Use your own data**: Load your own conversations as a list of `Conversation`\n",
    "  objects and use them to set up the simulation.\n",
    "  2. **Production features**: See `persistent_storage_example.ipynb` for persistent\n",
    "  storage with Chroma and advanced configurations suitable for larger datasets and\n",
    "  production use.\n",
    "  3. **Explore advanced features**: Check out the full documentation for more options\n",
    "  like caching of LLM responses, LLM failures handling, and more.\n",
    "\n",
    "  ### Resources:\n",
    "  - [Full documentation](https://github.com/SparkBeyond/agentune/blob/main/agentune_simulate/README.md)\n",
    "  - [Complete examples](https://github.com/SparkBeyond/agentune/tree/main/agentune_simulate/examples)\n",
    "  - [Persistent storage example](https://github.com/SparkBeyond/agentune/tree/main/agentune_simulate/examples/persistent_storage_example.ipynb)\n",
    "  - [Streamlit web interface](https://github.com/SparkBeyond/agentune/blob/main/agentune_simulate/streamlit/README.md)"
   ],
   "id": "9392b18526372ce7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
