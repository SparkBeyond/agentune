{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Getting Started with Agentune Simulate - Quick Start\n",
    "\n",
    "This notebook provides a streamlined introduction to the Agentune Simulate library. You'll learn to:\n",
    "\n",
    "- Load conversation data and extract outcomes\n",
    "- Set up RAG-based simulation with in-memory vector store\n",
    "- Run simulations and analyze results\n",
    "\n",
    "**Note**: This is a simplified version. For persistent storage and production features, see `persistent_storage_example.ipynb`."
   ],
   "id": "3b56a7f050e74e1c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Setup and Imports",
   "id": "c5dded46ebf63cbb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T07:19:33.714851Z",
     "start_time": "2025-07-23T07:19:30.010353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import getpass\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "from agentune.simulate.models import Outcomes\n",
    "from agentune.simulate.rag import conversations_to_langchain_documents\n",
    "from agentune.simulate.simulation.session_builder import SimulationSessionBuilder\n",
    "from utils import setup_logging_and_asyncio, load_data_with_outcomes"
   ],
   "id": "bd246a309270975d",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## API Key Configuration",
   "id": "a8df6f7fe2baca8c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T07:19:36.118443Z",
     "start_time": "2025-07-23T07:19:34.063665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set up OpenAI API key\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "\n",
    "print(\"✓ API key configured\")"
   ],
   "id": "9ba274b7835ecb11",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ API key configured\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Environment Setup",
   "id": "d550f89d948ce7d9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T07:19:36.129148Z",
     "start_time": "2025-07-23T07:19:36.126869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configure logging and asyncio for Jupyter\n",
    "setup_logging_and_asyncio()"
   ],
   "id": "390a21b0f2f61bc3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Logging configured\n",
      "✓ Asyncio event loop configured for Jupyter\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Data and Extract Outcomes",
   "id": "7b0efc2109f9a12c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T07:19:37.318293Z",
     "start_time": "2025-07-23T07:19:37.220430Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load conversations and extract outcomes in one step\n",
    "conversations, outcomes_tuple = load_data_with_outcomes(\"data/sample_conversations.csv\")\n",
    "outcomes = Outcomes(outcomes=outcomes_tuple)"
   ],
   "id": "c9248c937a5fdf38",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading conversations from data/sample_conversations.csv...\n",
      "✓ Loaded 100 conversations\n",
      "✓ Sample conversation has 6 messages\n",
      "✓ Extracted 2 unique outcomes\n",
      "  - resolved: Issue was successfully resolved\n",
      "  - unresolved: Issue was not resolved\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create Models and Vector Store",
   "id": "cb1e1de9817811a4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T07:19:41.743896Z",
     "start_time": "2025-07-23T07:19:38.432667Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Setup models\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o\", temperature=0.7)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Create in-memory vector store\n",
    "documents = conversations_to_langchain_documents(conversations)\n",
    "vector_store = InMemoryVectorStore.from_documents(documents, embeddings)\n",
    "\n",
    "print(f\"✓ Created vector store with {len(documents)} documents\")"
   ],
   "id": "82d6540e219aa9e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created vector store with 409 documents\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Run Simulation",
   "id": "6b1163d793a32dd1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T07:20:30.227359Z",
     "start_time": "2025-07-23T07:19:41.753690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Build and run simulation session\n",
    "session = SimulationSessionBuilder(\n",
    "    default_chat_model=chat_model,\n",
    "    outcomes=outcomes,\n",
    "    vector_store=vector_store,\n",
    "    max_messages=10\n",
    ").build()\n",
    "\n",
    "# Run simulation with first 5 conversations as starting points\n",
    "base_conversations = conversations[:5]\n",
    "result = await session.run_simulation(real_conversations=base_conversations)\n",
    "\n",
    "print(\"✓ Simulation completed!\")"
   ],
   "id": "df07e6e3c02dc028",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-23 10:19:41,755 - Starting intent extraction on 5 conversations\n",
      "2025-07-23 10:19:46,194 - Finished extracting original intents; generated 5 scenarios\n",
      "2025-07-23 10:19:46,195 - Starting conversation simulations (self.max_concurrent_conversations=20)\n",
      "2025-07-23 10:19:51,197 - Progress: 0/5 scenarios completed\n",
      "2025-07-23 10:20:01,199 - Progress: 1/5 scenarios completed\n",
      "2025-07-23 10:20:16,202 - Progress: 2/5 scenarios completed\n",
      "2025-07-23 10:20:21,204 - Progress: 5/5 scenarios completed\n",
      "2025-07-23 10:20:21,206 - Finished simulating conversations; simulated 5 conversations, with 0 failures\n",
      "2025-07-23 10:20:21,208 - Starting analysis of simulation results\n",
      "2025-07-23 10:20:30,225 - Finished analyzing results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Simulation completed!\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Analyze Results",
   "id": "7612a20be8965270"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T07:20:30.241663Z",
     "start_time": "2025-07-23T07:20:30.238988Z"
    }
   },
   "cell_type": "code",
   "source": "print(result.generate_summary())",
   "id": "bbc250873b2ec9d6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "SIMULATION RESULTS\n",
      "========================================\n",
      "Session name: Simulation Session\n",
      "Original conversations: 5\n",
      "Simulated conversations: 5\n",
      "\n",
      "Average messages per conversation:\n",
      "  Original: 4.4\n",
      "  Simulated: 5.0\n",
      "\n",
      "Outcome distribution comparison:\n",
      "Outcome              Original        Simulated      \n",
      "--------------------------------------------------\n",
      "resolved               4 (80.0%)     4 (80.0%)\n",
      "unresolved             1 (20.0%)     1 (20.0%)\n",
      "\n",
      "Sample conversation (6 messages):\n",
      "  1. customer: Last night, I waited in line for 2 hours in the business office, but because I only had a copy of my...\n",
      "  2. agent: We're very sorry for the inconvenience and frustration you've experienced. I am from the Guangdong C...\n",
      "  3. customer: I've already been through enough hassle with this process. Why can't you resolve the issue directly ...\n",
      "  4. agent: I apologize for the inconvenience and understand your frustration. I will escalate your issue intern...\n",
      "  ... and 2 more messages\n",
      "========================================\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that you've completed a basic simulation:\n",
    "\n",
    "  1. **Use your own data**: Load your own conversations as a list of `Conversation`\n",
    "  objects and use them to set up the simulation.\n",
    "  2. **Production features**: See `persistent_storage_example.ipynb` for persistent\n",
    "  storage with Chroma and advanced configurations suitable for larger datasets and\n",
    "  production use.\n",
    "  3. **Explore advanced features**: Check out the full documentation for more options\n",
    "  like caching of LLM responses, LLM failures handling, and more.\n",
    "\n",
    "  ### Resources:\n",
    "  - [Full documentation](https://github.com/SparkBeyond/agentune/blob/main/agentune_simulate/README.md)\n",
    "  - [Complete examples](https://github.com/SparkBeyond/agentune/tree/main/agentune_simulate/examples)\n",
    "  - [Persistent storage example](https://github.com/SparkBeyond/agentune/tree/main/agentune_simulate/examples/persistent_storage_example.ipynb)\n",
    "  - [Streamlit web interface](https://github.com/SparkBeyond/agentune/blob/main/agentune_simulate/streamlit/README.md)"
   ],
   "id": "6adea4e078c54658"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "76af0307231433b8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
